{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f256944c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install x-unet\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5cbbefa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "\n",
    "def set_seed(seed: int = 0):\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cea752ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8d388a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "data_path = 'data'\n",
    "png_folder = os.path.join(data_path, 'images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "802e4a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "\n",
    "class HighFrequencyDataset(Dataset):\n",
    "    def __init__(self, images_path):\n",
    "        self.images_path = images_path\n",
    "        self.images = self.read_images()\n",
    "\n",
    "    def read_images(self) -> torch.Tensor:\n",
    "        image_file_paths = [f for f in os.listdir(self.images_path) if f.lower().endswith('.png')]\n",
    "        images = [Image.open(os.path.join(self.images_path, img_path)) for img_path in image_file_paths]\n",
    "        return self.transform_images(images)\n",
    "\n",
    "    def transform_images(self, images: list[Image]) -> torch.Tensor:\n",
    "        transform = T.Compose([\n",
    "            T.Resize((256, 256)),\n",
    "            T.ToTensor(),\n",
    "        ])\n",
    "        return torch.stack([transform(image) for image in images])\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> torch.Tensor:\n",
    "        return self.images[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b5864ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = HighFrequencyDataset(png_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2682e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataset, val_dataset = train_test_split(dataset, test_size=0.2, random_state=0)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "415966cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from x_unet import XUnet\n",
    "\n",
    "# Create an instance of the XUnet model\n",
    "unet = XUnet(\n",
    "    dim = 64,\n",
    "    channels = 1,\n",
    "    dim_mults = (1, 2, 4, 8),\n",
    "    nested_unet_depths = (7, 4, 2, 1),     # nested unet depths, from unet-squared paper\n",
    "    consolidate_upsample_fmaps = True,     # whether to consolidate outputs from all upsample blocks, used in unet-squared paper\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09275b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() and not args.cpu else \"cpu\")\n",
    "unet = unet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf07e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def add_gaussian_noise(x, std):\n",
    "    # x in [-1, 1]; scale to [-1,1] noise as well\n",
    "    noise = torch.randn_like(x) * std\n",
    "    return (x + noise).clamp(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffae4077",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, math, argparse, random\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import datasets, transforms, utils as vutils\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ----- utilities -----\n",
    "\n",
    "\n",
    "def to_device(batch, device):\n",
    "    if isinstance(batch, (list, tuple)):\n",
    "        return [to_device(x, device) for x in batch]\n",
    "    return batch.to(device, non_blocking=True)\n",
    "\n",
    "@torch.no_grad()\n",
    "def denoise_grid(model, noisy, *, nrow=8, clamp=True):\n",
    "    model.eval()\n",
    "    pred = model(noisy)\n",
    "    out = pred\n",
    "    if clamp:\n",
    "        out = out.clamp(-1, 1)\n",
    "    grid = vutils.make_grid(out, nrow=nrow, normalize=True, value_range=(-1, 1))\n",
    "    return grid\n",
    "\n",
    "# ----- training -----\n",
    "def train(args):\n",
    "    set_seed(args.seed)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() and not args.cpu else \"cpu\")\n",
    "\n",
    "    out_dir = Path(args.out_dir)\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    (out_dir / \"samples\").mkdir(exist_ok=True)\n",
    "\n",
    "    # data\n",
    "    train_set, test_set = get_cifar10(args.data, img_size=args.img_size)\n",
    "    train_loader = DataLoader(train_set, batch_size=args.batch_size, shuffle=True,\n",
    "                              num_workers=args.workers, pin_memory=True, drop_last=True)\n",
    "    val_loader = DataLoader(test_set, batch_size=args.batch_size, shuffle=False,\n",
    "                            num_workers=args.workers, pin_memory=True, drop_last=False)\n",
    "\n",
    "    # model: XUnet\n",
    "    # Common lucidrains API pattern: dim is base channels, dim_mults define UNet levels\n",
    "    model = XUnet(\n",
    "        dim=args.dim,                 # base feature dimension\n",
    "        channels=3,                   # RGB\n",
    "        dim_mults=(1, 2, 4, 8),       # 4-level UNet\n",
    "        # you can tweak additional kwargs if desired; defaults work well for CIFAR-like data\n",
    "    ).to(device)\n",
    "\n",
    "    # optimizer\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=args.lr, betas=(0.9, 0.99), weight_decay=1e-4)\n",
    "\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=not args.no_amp and device.type == \"cuda\")\n",
    "    global_step = 0\n",
    "\n",
    "    best_val = float(\"inf\")\n",
    "\n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        model.train()\n",
    "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch}/{args.epochs}\")\n",
    "        running = 0.0\n",
    "\n",
    "        for (x, _) in pbar:\n",
    "            x = to_device(x, device)          # clean target in [-1,1]\n",
    "            x_noisy = add_gaussian_noise(x, args.noise_std)\n",
    "\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "\n",
    "            with torch.autocast(device_type=device.type, dtype=torch.float16, enabled=scaler.is_enabled()):\n",
    "                pred = model(x_noisy)          # predict clean image directly\n",
    "                loss = F.mse_loss(pred, x)     # DAE loss\n",
    "\n",
    "            if scaler.is_enabled():\n",
    "                scaler.scale(loss).backward()\n",
    "                if args.clip_grad is not None:\n",
    "                    scaler.unscale_(opt)\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), args.clip_grad)\n",
    "                scaler.step(opt)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                loss.backward()\n",
    "                if args.clip_grad is not None:\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), args.clip_grad)\n",
    "                opt.step()\n",
    "\n",
    "            running += loss.item()\n",
    "            global_step += 1\n",
    "            pbar.set_postfix(loss=f\"{loss.item():.4f}\")\n",
    "\n",
    "            # sample preview\n",
    "            if global_step % args.sample_every == 0:\n",
    "                with torch.no_grad():\n",
    "                    grid = denoise_grid(model, x_noisy[:min(16, x_noisy.size(0))])\n",
    "                vutils.save_image(grid, out_dir / \"samples\" / f\"train_step{global_step:07d}.png\")\n",
    "\n",
    "        train_loss = running / len(train_loader)\n",
    "\n",
    "        # validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for (xv, _) in val_loader:\n",
    "                xv = to_device(xv, device)\n",
    "                xv_noisy = add_gaussian_noise(xv, args.noise_std)\n",
    "                pv = model(xv_noisy)\n",
    "                val_loss += F.mse_loss(pv, xv, reduction='mean').item()\n",
    "        val_loss /= len(val_loader)\n",
    "\n",
    "        # save checkpoint\n",
    "        ckpt_path = out_dir / f\"epoch{epoch:03d}_val{val_loss:.4f}.pt\"\n",
    "        torch.save({\n",
    "            \"epoch\": epoch,\n",
    "            \"model\": model.state_dict(),\n",
    "            \"opt\": opt.state_dict(),\n",
    "            \"scaler\": scaler.state_dict(),\n",
    "            \"args\": vars(args),\n",
    "            \"val_loss\": val_loss,\n",
    "        }, ckpt_path)\n",
    "\n",
    "        # track best\n",
    "        if val_loss < best_val:\n",
    "            best_val = val_loss\n",
    "            torch.save(model.state_dict(), out_dir / \"best_model.pt\")\n",
    "\n",
    "        print(f\"Epoch {epoch} | train {train_loss:.4f} | val {val_loss:.4f} | best {best_val:.4f}\")\n",
    "\n",
    "        # periodic validation samples\n",
    "        with torch.no_grad():\n",
    "            # take a small batch for visualization\n",
    "            xv, _ = next(iter(val_loader))\n",
    "            xv = to_device(xv, device)[:16]\n",
    "            xv_noisy = add_gaussian_noise(xv, args.noise_std)\n",
    "            grid_noisy = vutils.make_grid(xv_noisy, nrow=8, normalize=True, value_range=(-1,1))\n",
    "            grid_clean = vutils.make_grid(xv, nrow=8, normalize=True, value_range=(-1,1))\n",
    "            grid_deno  = denoise_grid(model, xv_noisy, nrow=8)\n",
    "\n",
    "            vutils.save_image(grid_noisy, out_dir / \"samples\" / f\"val_noisy_epoch{epoch:03d}.png\")\n",
    "            vutils.save_image(grid_deno,  out_dir / \"samples\" / f\"val_denoised_epoch{epoch:03d}.png\")\n",
    "            vutils.save_image(grid_clean, out_dir / \"samples\" / f\"val_clean_epoch{epoch:03d}.png\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description=\"Train X-UNet (lucidrains) for Gaussian denoising\")\n",
    "    parser.add_argument(\"--data\", type=str, default=\"./data\", help=\"dataset root\")\n",
    "    parser.add_argument(\"--out-dir\", type=str, default=\"./runs/xunet_denoise\", help=\"output directory\")\n",
    "    parser.add_argument(\"--img-size\", type=int, default=32, help=\"image side length\")\n",
    "    parser.add_argument(\"--epochs\", type=int, default=50)\n",
    "    parser.add_argument(\"--batch-size\", type=int, default=128)\n",
    "    parser.add_argument(\"--workers\", type=int, default=4)\n",
    "    parser.add_argument(\"--lr\", type=float, default=2e-4)\n",
    "    parser.add_argument(\"--dim\", type=int, default=64, help=\"X-UNet base channels\")\n",
    "    parser.add_argument(\"--noise-std\", type=float, default=0.2, help=\"Gaussian noise std (in [-1,1] scale)\")\n",
    "    parser.add_argument(\"--sample-every\", type=int, default=500, help=\"steps between training previews\")\n",
    "    parser.add_argument(\"--clip-grad\", type=float, default=None, help=\"e.g., 1.0 for grad clipping\")\n",
    "    parser.add_argument(\"--seed\", type=int, default=42)\n",
    "    parser.add_argument(\"--cpu\", action=\"store_true\", help=\"force CPU\")\n",
    "    parser.add_argument(\"--no-amp\", action=\"store_true\", help=\"disable mixed precision\")\n",
    "    args = parser.parse_args()\n",
    "    train(args)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
